{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sin1 freq:[1, 3], phase:[-1.5707963267948966, 0]\n",
      "sin2 freq:[4, 6], phase:[0, 1.5707963267948966]\n",
      "sin1 freq:[1, 3], phase:[-1.5707963267948966, 0]\n",
      "sin2 freq:[4, 6], phase:[0, 1.5707963267948966]\n",
      "600\n",
      "torch.Size([100, 3])\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "from architectures.timegan_cnn_DG import *\n",
    "from utils import *\n",
    "from trainers import *\n",
    "import numpy as np\n",
    "np.random.seed(455)\n",
    "\n",
    "trainset = DatasetSinus(num=600, seq_len=100, alpha=0.7, noise=0)\n",
    "testset = DatasetSinus(num=600, seq_len=100, alpha=0.7, noise=0)\n",
    "print(len(trainset))\n",
    "print(trainset[0][0].size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/kohmann/timeGAN/e/TIMEGAN-215\n",
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n",
      "\n",
      "Start Embedding Network Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 499, Loss: 0.0101: 100%|██████████| 500/500 [01:28<00:00,  5.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start Training with Supervised Loss Only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 499, Loss: 0.0045: 100%|██████████| 500/500 [01:04<00:00,  7.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start Joint Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 239, E: 0.2318, G: 4.6149, D: 0.1700:  12%|█▏        | 240/2000 [05:05<40:01,  1.36s/it]"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "import neptune.new as neptune\n",
    "import torch\n",
    "\n",
    "run = neptune.init_run(\n",
    "    project=\"kohmann/timeGAN\",\n",
    "    name=\"timegan_cnn_DG\",\n",
    "    tags=[\"cnn\",\"DG\"],\n",
    "    description=\"On updated sinus set\",\n",
    "    source_files=[\"timegan_cnn_DG.py\"],\n",
    "    capture_hardware_metrics=False,\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI3YjFjNGY5MS1kOWU1LTRmZjgtOTNiYS0yOGI2NDdjZGYzNWUifQ==\",\n",
    ")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "params = {\n",
    "    \"model_name\": \"model_cnn_dg.pt\",\n",
    "    \"n_epochs\": 2000,\n",
    "    \"l_rate\": 0.001,\n",
    "    \"l_rate_ae\": 0.001,\n",
    "    \"batch_size\": 64,\n",
    "    \"num_layers\": 2,\n",
    "    \"hidden_dim\": 20,\n",
    "    \"Z_dim\": 100,\n",
    "    \"dis_thresh\": 0.15,\n",
    "    \"dataset\": \"sinus\",\n",
    "    \"feature_dim\": trainset[0][0].size(1),\n",
    "    \"max_seq_len\": trainset[0][0].size(0),\n",
    "    \"trainset_size\": len(trainset),\n",
    "    \"device\": device,\n",
    "    \"optimizer\": \"Adam\",\n",
    "}\n",
    "run[\"parameters\"] = params\n",
    "\n",
    "model = TimeGAN(params)\n",
    "timegan_trainer(model, trainset, params, neptune_logger=run, continue_training=False)\n",
    "\n",
    "# Generate random synthetic data\n",
    "gen_z = timegan_generator(model, torch.tensor(testset.T), params[\"model_name\"], torch.device(device), testset[0][0].size(0), 100)\n",
    "\n",
    "log_visualizations(testset, gen_z, run) # logs pca, tsne, umap, mode_collapse\n",
    "run[\"model_checkpoint\"].upload(params[\"model_name\"])\n",
    "\n",
    "run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = 10\n",
    "plt.plot(gen_z[sample][:, 0], label=\"gen_sin1\")\n",
    "plt.plot(gen_z[sample][:, 1], label=\"gen_sin2\")\n",
    "plt.plot(gen_z[sample][:, 2], label=\"gen_sin3\")\n",
    "plt.title(\"Generated sampels\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_sin3(sin1, sin2, temporal=False):\n",
    "    sin1, sin2 = np.array(sin1), np.array(sin2)\n",
    "    e = 0.7  # temporal information weight\n",
    "    seq_len = len(sin1)\n",
    "    importance = np.array([e ** i for i in range(seq_len)])\n",
    "\n",
    "    if temporal:\n",
    "        sin3 = []\n",
    "        for i in range(1, seq_len + 1):\n",
    "            sin3.append(((importance[:i][::-1] * sin1[:i] + importance[:i][::-1] * sin2[:i]) / 2).sum())\n",
    "        return sin3\n",
    "    else:\n",
    "        return [(s1 + s2) / 2 for s1, s2 in zip(sin1, sin2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = 6\n",
    "real_combo = create_sin3(gen_z[sample][:,0], gen_z[sample][:,1], temporal=True)\n",
    "real_comb_scaled = minmaxscaler().fit_transform(torch.tensor([real_combo]))[0]\n",
    "gen_combo = gen_z[sample][:,2]\n",
    "plt.plot(real_comb_scaled, label=\"true sim3\")\n",
    "plt.plot(gen_combo, label=\"generated sim3\")\n",
    "plt.title(\"sim3 - true vs generated\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = trainset.__getitem__(9)\n",
    "plt.plot(sample[0][:,0], label=\"sin1\")\n",
    "plt.plot(sample[0][:,1], label=\"sin2\")\n",
    "plt.plot(sample[0][:,2], label=\"(sin1 + sin2)/2\")\n",
    "plt.title(\"Real data\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_comb = create_sin3(gen_z[sample][:,0], gen_z[sample][:,0], temporal=True)\n",
    "real_comb_scaled = minmaxscaler().fit_transform(torch.tensor([real_combo]))\n",
    "plt.plot(real_comb_scaled[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN layer testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def printLayerShapes(layers, input):\n",
    "    for layer in layers:\n",
    "        output = layer(input)\n",
    "\n",
    "        print(f\"{type(layer).__name__:13}: {list(input.size())} --> {list(output.size())}\")\n",
    "        input = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "hidden_dim = 20\n",
    "max_seq_len = 100\n",
    "input = torch.randn(2, max_seq_len, hidden_dim)\n",
    "\n",
    "\n",
    "## Discriminator\n",
    "layers = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=100, out_channels=20, kernel_size=(5), stride=2, bias=False)\n",
    "            , nn.BatchNorm1d(20)\n",
    "            , nn.LeakyReLU()\n",
    "            , nn.Conv1d(in_channels=20, out_channels=40, kernel_size=(7), stride=2, bias=False)\n",
    "            , nn.BatchNorm1d(40)\n",
    "            , nn.LeakyReLU()\n",
    "            , nn.Flatten(start_dim=1)\n",
    "            , nn.Linear(40, 1)\n",
    "        )\n",
    "print(f\"Discriminator architecture\\nInput: {input.size()}\\n\")\n",
    "printLayerShapes(layers, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "## Generator architecture\n",
    "Z_dim = 100\n",
    "hidden_dim = 20\n",
    "max_seq_len = 100\n",
    "input = torch.randn(2, max_seq_len, Z_dim)\n",
    "\n",
    "\n",
    "layers = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=100, out_channels=100, kernel_size=(6), stride=2, bias=False)\n",
    "            , nn.BatchNorm1d(100)\n",
    "            , nn.LeakyReLU()\n",
    "            , nn.Conv1d(in_channels=100, out_channels=100, kernel_size=(9), stride=2, bias=True)\n",
    "            , nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "print(f\"Generator architecture\\nInput: {input.size()}\\n\")\n",
    "printLayerShapes(layers, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "## Generator architecture LINEAR\n",
    "Z_dim = 1\n",
    "hidden_dim = 20\n",
    "max_seq_len = 100\n",
    "input = torch.randn(16, max_seq_len, Z_dim)\n",
    "input = input.squeeze(dim=2)\n",
    "\n",
    "\n",
    "layers = nn.Sequential(\n",
    "            nn.Linear(in_features=100, out_features=200, bias=True)\n",
    "            ,nn.LayerNorm(200)\n",
    "            ,nn.LeakyReLU()\n",
    "            ,nn.Linear(in_features=200, out_features=400, bias=True)\n",
    "            ,nn.LayerNorm(400)\n",
    "            ,nn.LeakyReLU()\n",
    "            ,nn.Linear(in_features=200, out_features=1000, bias=True)\n",
    "            ,nn.LayerNorm(400)\n",
    "            ,nn.LeakyReLU()\n",
    "        )\n",
    "\n",
    "\n",
    "print(f\"Generator architecture\\nInput: {input.size()}\\n\")\n",
    "printLayerShapes(layers, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "torch.randn(16,300).view(-1,100,3).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
