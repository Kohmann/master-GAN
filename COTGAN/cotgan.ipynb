{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sin1 freq:[1, 3], phase:[-1.5707963267948966, 0]\n",
      "sin2 freq:[4, 6], phase:[0, 1.5707963267948966]\n",
      "sin1 freq:[1, 3], phase:[-1.5707963267948966, 0]\n",
      "sin2 freq:[4, 6], phase:[0, 1.5707963267948966]\n",
      "384\n",
      "torch.Size([25, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": "'cpu'"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%autoreload\n",
    "from architectures import COTGAN\n",
    "from utils import DatasetSinus, log_visualizations\n",
    "from trainer import cotgan_trainer, cotgan_generator\n",
    "from metrics import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seed = 42\n",
    "alpha = 0.7\n",
    "noise = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "if torch.backends.mps.is_available(): # run on M1 mac\n",
    "    device = \"mps\"\n",
    "elif torch.cuda.is_available(): # cuda\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "device = \"cpu\"\n",
    "trainset = DatasetSinus(num=32*2*12, seq_len=25, alpha=alpha, noise=noise, device=device)\n",
    "testset = DatasetSinus(num=32*2*6, seq_len=25, alpha=alpha, noise=noise, device=\"cpu\")\n",
    "\n",
    "print(len(testset))\n",
    "print(testset[0][0].size())\n",
    "\n",
    "#plt.plot(trainset[1][0]);\n",
    "device"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/kohmann/COTGAN/e/COT-183\n",
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 115, G: 2.4556, D: 2.0054:  39%|███▊      | 116/300 [07:16<11:39,  3.80s/it]"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "import neptune.new as neptune\n",
    "\n",
    "run = neptune.init_run(\n",
    "    project=\"kohmann/COTGAN\",\n",
    "    name=\"cotgan\",\n",
    "    tags=[\"tuning\"],\n",
    "    description=\"\",\n",
    "    source_files=[\"architectures.py\"],\n",
    "    capture_hardware_metrics=True,\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI3YjFjNGY5MS1kOWU1LTRmZjgtOTNiYS0yOGI2NDdjZGYzNWUifQ==\",\n",
    ")\n",
    "\n",
    "params = {\n",
    "    \"model_name\": \"model_cotgan.pt\",\n",
    "    \"n_epochs\": 300,\n",
    "    \"l_rate\":   0.001, # for both D and G\n",
    "    \"l_rate_g\": 0.001, # for G only\n",
    "    \"batch_size\": 32,\n",
    "\n",
    "    \"rnn_type\": \"GRU\", # LSTM, GRU\n",
    "    \"dis_rnn_num_layers\": 2,\n",
    "    \"dis_rnn_hidden_dim\": 64,\n",
    "    \"gen_rnn_num_layers\": 2,\n",
    "    \"gen_rnn_hidden_dim\": 64,\n",
    "    \"hidden_dim\": 64*2, # generator: hidden dim in FC, discriminator: filters in Convolution\n",
    "    \"num_hidden_layers\": 2, # generator fully-connected layers\n",
    "    \"use_bn\": False, # batch normalization\n",
    "\n",
    "    \"scaling_coef\": 1.0, # distance scaling (TODO(Not implemented))\n",
    "    \"reg_lam\":      0.01, # martingale penalty coefficient\n",
    "    \"sinkhorn_eps\": 10.0, # epsilon regularizer\n",
    "    \"sinkhorn_l\":   100, # sinkhorn calculation iterations\n",
    "\n",
    "    \"Z_dim\": 100,\n",
    "    \"optimizer\": \"Adam\", # RMSprop, Adam\n",
    "    \"beta1\": 0.5,\n",
    "    \"beta2\": 0.9,\n",
    "    \"dataset\": \"sines\",\n",
    "    \"feature_dim\": trainset[0][0].size(1),\n",
    "    \"max_seq_len\": trainset[0][0].size(0),\n",
    "    \"trainset_size\": len(trainset),\n",
    "    \"testset_size\": len(testset),\n",
    "    \"device\": device,\n",
    "}\n",
    "\n",
    "run[\"parameters\"] = params\n",
    "run[\"dataset\"] = {\"alpha\":alpha, \"noise\":noise,\n",
    "                  \"s1_freq\": trainset.s1_freq, \"s1_phase\": trainset.s1_phase,\n",
    "                  \"s2_freq\": trainset.s2_freq, \"s2_phase\": trainset.s2_phase}\n",
    "\n",
    "model = COTGAN(params)\n",
    "cotgan_trainer(model, trainset, params, val_dataset=testset, neptune_logger=run, continue_training=False)\n",
    "\n",
    "\n",
    "# Generate random synthetic data\n",
    "gen_z = cotgan_generator(model, params)\n",
    "\n",
    "log_visualizations(testset, gen_z, run) # log pca, tsne, umap, mode_collapse\n",
    "run[\"model_checkpoint\"].upload(\"./models/\" + params[\"model_name\"])\n",
    "\n",
    "from metrics import compare_sin3_generation, sw_approx\n",
    "np.random.seed(seed + 1)\n",
    "torch.manual_seed(seed + 1)\n",
    "testset2 = DatasetSinus(num=params[\"testset_size\"], seq_len=params[\"max_seq_len\"], alpha=alpha, noise=noise, device=\"cpu\")\n",
    "fake_data = cotgan_generator(model, params)\n",
    "\n",
    "mse_error = compare_sin3_generation(fake_data, alpha, noise)\n",
    "print(f\"MSE Error: {mse_error:.5f}\")\n",
    "x = torch.tensor(fake_data)\n",
    "y = testset[:][0]\n",
    "y_2 = testset2[:][0]\n",
    "\n",
    "sw_baseline = sw_approx(y,y_2)\n",
    "sw = sw_approx(y,x)\n",
    "\n",
    "run[\"numeric_results/num_test_samples\"] = len(testset)\n",
    "run[\"numeric_results/sin3_generation_MSE_loss\"] = mse_error\n",
    "run[\"numeric_results/SW\"] = sw.item()\n",
    "run[\"numeric_results/SW_baseline\"] = sw_baseline.item()\n",
    "run.stop()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
