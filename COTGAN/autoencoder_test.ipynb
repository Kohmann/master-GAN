{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from architectures import SolitonGenerator, SolitonDiscriminator\n",
    "import neptune.new as neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"n_samples\": 1920,\n",
    "    \"n_epochs\": 600,\n",
    "    \"device\": \"cpu\",\n",
    "    \"batch_size\": 32,\n",
    "    \"Z_dim\": 10,\n",
    "    \"J_dim\": 10,\n",
    "    \"hidden_dim\": 64, # 256\n",
    "    \"gen_rnn_hidden_dim\": 64,\n",
    "    \"gen_rnn_num_layers\": 2,\n",
    "    #\"dis_rnn_hidden_dim\": 100,\n",
    "    #\"dis_rnn_num_layers\": 2,\n",
    "    \"num_hidden_layers\": 3,\n",
    "    \"feature_dim\": 120,\n",
    "    \"max_seq_len\": 30,\n",
    "    \"rnn_type\": \"GRU\",\n",
    "    \"use_bn\": False,\n",
    "    \"P\": 50,\n",
    "    \"spatial_len\": 120,\n",
    "    \"dx\": 120,\n",
    "    \"dt\": 30,\n",
    "    \"t_steps\": 30,\n",
    "    \"eta\": 6.0,\n",
    "    \"gamma\": 1.0,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: twosolitons\n",
      "Loading dataset: Two Solitons\n",
      "RAW data: (1000, 360, 360), MB: 518.4\n",
      "\tDownsampled:(1000, 30, 120), MB: 14.4\n",
      "RAW data: (1000, 360, 360), MB: 518.4\n",
      "\tDownsampled:(1000, 30, 120), MB: 14.4\n",
      "RAW data: (1000, 360, 360), MB: 518.4\n",
      "\tDownsampled:(1000, 30, 120), MB: 14.4\n",
      "Concatenated data with shape (3000, 30, 120) and size: 43.2 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": "torch.Size([1920, 30, 120])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trainer import create_dataset\n",
    "dataset = create_dataset(\"twosolitons\", args[\"n_samples\"], args, args[\"device\"] )\n",
    "dataset[:].size()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "SolitonGenerator(\n  (gen_rnn): GRU(10, 64, batch_first=True)\n  (gen_rnn2): GRU(64, 128, batch_first=True)\n  (gen_FC): Sequential(\n    (0): Linear(in_features=128, out_features=64, bias=True)\n    (1): LeakyReLU(negative_slope=0.01)\n    (2): Linear(in_features=64, out_features=64, bias=True)\n    (3): LeakyReLU(negative_slope=0.01)\n    (4): Linear(in_features=64, out_features=120, bias=True)\n    (5): Sigmoid()\n  )\n)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SolitonGenerator(args)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "encoder = SolitonDiscriminator(args)\n",
    "encoder.to(args[\"device\"])\n",
    "decoder = SolitonGenerator(args)\n",
    "decoder.to(args[\"device\"])\n",
    "\n",
    "z = encoder(dataset[:args[\"batch_size\"]])\n",
    "x_hat = decoder(z)\n",
    "x_hat.size()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 30, 10])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.args = args\n",
    "        self.rnn = torch.nn.GRU(\n",
    "            input_size=args[\"dx\"],\n",
    "            hidden_size=args[\"gen_rnn_hidden_dim\"],\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(args[\"gen_rnn_hidden_dim\"], 256),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(256, 256),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(256, args[\"Z_dim\"]),\n",
    "            torch.nn.Tanh() # To make sure that the values are in [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.rnn(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "encoder_test = Encoder(args)\n",
    "encoder_test(dataset[:1]).size()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/kohmann/autoencoder/e/AUT-44\n",
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0, MSE: 0.0204:   0%|          | 0/600 [00:01<?, ?it/s]/Users/kohmann/Documents/Studie/2022 Høst/master-GAN/venv/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:381: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current learning rate:  [0.001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 200, MSE: 0.0015:  33%|███▎      | 200/600 [05:12<09:30,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current learning rate:  [0.001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 400, MSE: 0.0001:  67%|██████▋   | 400/600 [10:14<04:46,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current learning rate:  [0.001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 599, MSE: 0.0001: 100%|██████████| 600/600 [15:24<00:00,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n",
      "Waiting for the remaining 24 operations to synchronize with Neptune. Do not kill this process.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 24 operations synced, thanks for waiting!\n",
      "Explore the metadata in the Neptune app:\n",
      "https://app.neptune.ai/kohmann/autoencoder/e/AUT-44\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "from metrics import energy_conservation, mass_conservation, momentum_conservation\n",
    "\n",
    "neptune_logger =  neptune.init_run(\n",
    "        project=\"kohmann/autoencoder\",\n",
    "        name=\"autoencoder_test\",\n",
    "        tags=[\"tuning\"],\n",
    "        description=\"\",\n",
    "        capture_hardware_metrics=True,\n",
    "        api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI3YjFjNGY5MS1kOWU1LTRmZjgtOTNiYS0yOGI2NDdjZGYzNWUifQ==\",\n",
    "    )\n",
    "\n",
    "def eval(x_hat, args, neptune_logger, title=\"train\"):\n",
    "    dx = args[\"P\"]/args[\"spatial_len\"] # P / M\n",
    "    H_error = energy_conservation(x_hat, dx=dx, eta=args[\"eta\"], gamma=args[\"gamma\"]).mean().item()\n",
    "    H_mass_error     = mass_conservation(x_hat, dx=dx).mean().item()\n",
    "    H_momentum_error = momentum_conservation(x_hat, dx=dx).mean().item()\n",
    "\n",
    "    neptune_logger[\"H_mean_error_\" + title].log(H_error)\n",
    "    neptune_logger[\"H_mass_error_\"  + title].log(H_mass_error)\n",
    "    neptune_logger[\"H_momentum_error_\"  + title].log(H_momentum_error)\n",
    "\n",
    "def train(args, neptune_logger=None):\n",
    "    device = args[\"device\"]\n",
    "\n",
    "    neptune_logger[\"parameters\"] = args\n",
    "\n",
    "    encoder = Encoder(args)\n",
    "    decoder = SolitonGenerator(args)\n",
    "\n",
    "    encoder.to(device)\n",
    "    decoder.to(device)\n",
    "\n",
    "\n",
    "    train_data = torch.utils.data.DataLoader(\n",
    "            dataset=dataset[:int(args[\"n_samples\"] * 0.8)],\n",
    "            batch_size=args[\"batch_size\"],\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        list(encoder.parameters()) + list(decoder.parameters()), lr=0.001\n",
    "    )\n",
    "    # add scheduler that decays the learning rate every 200 epochs\n",
    "    scheduler_opt = torch.optim.lr_scheduler.StepLR(optimizer, step_size=200, gamma=0.1)\n",
    "    loss = torch.nn.MSELoss()\n",
    "    train_data_test = dataset[:int(args[\"n_samples\"] * 0.8)]\n",
    "    test_data_test = dataset[int(args[\"n_samples\"] * 0.8):]\n",
    "\n",
    "    logger = trange(args[\"n_epochs\"], desc=f\"Epoch: 0, MSE: 0\")\n",
    "    for epoch in logger:\n",
    "        batch_losses = 0\n",
    "        for x in train_data:\n",
    "            optimizer.zero_grad()\n",
    "            x = x.to(device)\n",
    "            z = encoder(x)\n",
    "            x_hat = decoder(z)\n",
    "            loss_value = loss(x_hat, x)\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            #scheduler_opt.step()\n",
    "            # print current learning rate after each 200 epoch\n",
    "\n",
    "            batch_losses += loss_value.detach().item()\n",
    "        logger.set_description(f\"Epoch: {epoch}, MSE: {loss_value.item():.4f}\")\n",
    "        mean_loss = batch_losses / (args[\"n_samples\"] / args[\"batch_size\"])\n",
    "        if epoch % 200 == 0:\n",
    "                print('Current learning rate: ', scheduler_opt.get_lr())\n",
    "        with torch.no_grad():\n",
    "            z_train = encoder(train_data_test)\n",
    "            fake_train = decoder(z_train).detach().cpu()\n",
    "            z_test = encoder(test_data_test)\n",
    "            fake_test = decoder(z_test).detach().cpu()\n",
    "            mse_test = loss(fake_test, test_data_test).item()\n",
    "\n",
    "        fig, axs = plt.subplots(3, 3, figsize=(14, 10))\n",
    "        for x in range(3):\n",
    "            for y in range(3):\n",
    "                axs[x, y].plot(fake_test[x * 3 + y].T.cpu())\n",
    "                axs[x, y].set_ylim([0, 1])\n",
    "\n",
    "        fig.suptitle(f\"Generation: {epoch}\", fontsize=14)\n",
    "        neptune_logger[\"generated_image\"].log(fig)\n",
    "        plt.close(fig)\n",
    "        eval(fake_train, args, neptune_logger, title=\"train\")\n",
    "        eval(fake_test,  args, neptune_logger, title=\"test\")\n",
    "\n",
    "        neptune_logger[\"MSE_train\"].log(mean_loss)\n",
    "        neptune_logger[\"MSE_test\"].log(mse_test)\n",
    "    return encoder, decoder\n",
    "encoder, decoder = train(args, neptune_logger=neptune_logger)\n",
    "neptune_logger.stop()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot some results using the logger"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import animation, rc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def animate_single(data, title):\n",
    "    rc('animation', html='jshtml')\n",
    "    fig, ax = plt.subplots()\n",
    "    line, = ax.plot([], [], lw=2)\n",
    "    ax.set_xlim((0, data.shape[1]))\n",
    "    ax.set_ylim((0, 1))\n",
    "    ax.set_xlabel('$x$', fontsize=12)\n",
    "    ax.set_ylabel('$u$', fontsize=12)\n",
    "    ax.grid()\n",
    "    plt.title(title)\n",
    "    #x = np.arange(data.shape[1])\n",
    "    x = torch.arange(data.shape[1])\n",
    "    def init():\n",
    "        line.set_data([], [])\n",
    "        return (line,)\n",
    "    def animate(i):\n",
    "        line.set_data(x, data[i,:])\n",
    "        return (line,)\n",
    "    ani = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                                  frames=data.shape[0], interval=20, blit=True)\n",
    "    ani.save('plots/' + title + '.gif', fps=15)\n",
    "\n",
    "n = 8\n",
    "ani = animate_single(dataset[n].detach().numpy(), \"Real3\")\n",
    "z = encoder(dataset[n])\n",
    "x_hat = decoder(z)\n",
    "ani = animate_single(x_hat.detach().numpy(), \"Reconstructed3\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load best model\n",
    "#torch.save(encoder.state_dict(), \"models/encoder-AUT25.pt\")\n",
    "#torch.save(decoder.state_dict(), \"models/decoder-AUT25.pt\")\n",
    "\n",
    "encoder = Encoder(args)\n",
    "decoder = SolitonGenerator(args)\n",
    "encoder.load_state_dict(torch.load(\"models/encoder-AUT25.pt\"))\n",
    "decoder.load_state_dict(torch.load(\"models/decoder-AUT25.pt\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
